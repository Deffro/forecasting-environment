{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58bcca3-24bc-490d-936b-08984803d334",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce1f6b7-0739-4e0c-90c1-34a407590089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sktime\n",
    "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.forecasting.arima import AutoARIMA, ARIMA\n",
    "from sktime.forecasting.compose import MultiplexForecaster, AutoEnsembleForecaster, ColumnEnsembleForecaster, DirRecTabularRegressionForecaster, RecursiveTabularRegressionForecaster, DirRecTimeSeriesRegressionForecaster, DirectTabularRegressionForecaster, DirectTimeSeriesRegressionForecaster, EnsembleForecaster, StackingForecaster\n",
    "from sktime.forecasting.ets import AutoETS\n",
    "from sktime.forecasting.theta import ThetaForecaster\n",
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.transformations.series.compose import ColumnwiseTransformer\n",
    "from sktime.transformations.series.adapt import TabularToSeriesAdaptor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sktime.performance_metrics.forecasting import MeanSquaredError, MeanAbsoluteScaledError, mean_absolute_percentage_error, MeanAbsoluteError\n",
    "from sktime.forecasting.model_evaluation import evaluate\n",
    "from sktime.forecasting.model_selection import ExpandingWindowSplitter, ForecastingGridSearchCV\n",
    "from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "from sktime.transformations.series.detrend import Deseasonalizer, Detrender\n",
    "from sktime.transformations.series.difference import Differencer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, Lars, LassoLars, BayesianRidge, HuberRegressor, PassiveAggressiveRegressor, OrthogonalMatchingPursuit\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "import lightgbm as lgbm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becc6122-38e6-4003-aa61-7c1b3bf10a72",
   "metadata": {},
   "source": [
    "## Algorithm parameters to tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ea75be-04b8-4875-b3d4-fa24591d274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = {\n",
    "    'decision_tree': {\n",
    "        'estimator': \n",
    "            DecisionTreeRegressor(ccp_alpha=0.0,  criterion='mse', max_depth=None, max_features=None, max_leaf_nodes=None, \n",
    "                                  min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, \n",
    "                                  min_weight_fraction_leaf=0.0, random_state=42, splitter='best')\n",
    "        ,\n",
    "        'params': {\n",
    "            'forecaster__estimator__ccp_alpha': [0, 0.01, 0.1],\n",
    "            'forecaster__estimator__max_depth': [1, 2, 3, 4, 5, 10, None],\n",
    "            'forecaster__estimator__max_leaf_nodes': [3, 8, 16, 100, None],\n",
    "            'forecaster__estimator__min_impurity_decrease': [0, 0.01, 0.1],\n",
    "            'forecaster__estimator__min_samples_leaf': [1, 2, 3, 4],\n",
    "            'forecaster__estimator__min_samples_split': [2, 3]            \n",
    "        }     \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'estimator': \n",
    "            RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse', max_depth=None, max_features='auto', \n",
    "                                  max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, \n",
    "                                  min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, \n",
    "                                  n_jobs=-1, oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
    "        ,\n",
    "        'params': {\n",
    "            'forecaster__estimator__ccp_alpha': [0, 0.01, 0.1],\n",
    "            'forecaster__estimator__max_depth': [1, 2, 3, 4, 5, 10, None],\n",
    "            'forecaster__estimator__max_leaf_nodes': [3, 8, 16, 100, None],\n",
    "            'forecaster__estimator__min_impurity_decrease': [0, 0.01, 0.1],\n",
    "            'forecaster__estimator__min_samples_leaf': [1, 2, 3, 4],\n",
    "            'forecaster__estimator__min_samples_split': [1, 2, 3],\n",
    "            'forecaster__estimator__n_estimators': [10, 50, 100, 200],        \n",
    "        }     \n",
    "    },    \n",
    "    'extra_trees': {\n",
    "        'estimator': \n",
    "            ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse', max_depth=None, max_features='auto', \n",
    "                                max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, \n",
    "                                min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, \n",
    "                                n_jobs=-1, oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
    "        ,\n",
    "        'params': {\n",
    "            'forecaster__estimator__ccp_alpha': [0, 0.01, 0.1],\n",
    "            'forecaster__estimator__max_depth': [1, 2, 3, 4, 5, 10, -1],\n",
    "            'forecaster__estimator__max_leaf_nodes': [3, 8, 16, 100, -1],\n",
    "            'forecaster__estimator__min_impurity_decrease': [0, 0.01, 0.1],\n",
    "            'forecaster__estimator__min_samples_leaf': [1, 2, 3, 4],\n",
    "            'forecaster__estimator__min_samples_split': [1, 2, 3],\n",
    "            'forecaster__estimator__n_estimators': [10, 50, 100],\n",
    "            'forecaster__estimator__warm_start': [True, False],     \n",
    "        }     \n",
    "    },     \n",
    "    'gradient_boosting': {\n",
    "        'estimator': \n",
    "            GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse', init=None, learning_rate=0.1, loss='ls', \n",
    "                                      max_depth=3, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, \n",
    "                                      min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_iter_no_change=None, \n",
    "                                      random_state=42, subsample=1.0, tol=0.0001, validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "        ,\n",
    "        'params': {\n",
    "            'forecaster__estimator__alpha': [0.5, 0.9],\n",
    "            'forecaster__estimator__ccp_alpha': [0, 0.01, 0.1],\n",
    "            'forecaster__estimator__max_depth': [2, 3, 5, 10, -1],\n",
    "            'forecaster__estimator__min_impurity_decrease': [0, 0.01, 0.1],\n",
    "            'forecaster__estimator__min_samples_leaf': [1, 2],\n",
    "            'forecaster__estimator__min_samples_split': [2, 3],\n",
    "            'forecaster__estimator__n_estimators': [10, 100, 200],\n",
    "            'forecaster__estimator__learning_rate': [0.1, 0.01], \n",
    "        }     \n",
    "    },       \n",
    "    'adaboost': {\n",
    "        'estimator': \n",
    "            AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear', n_estimators=50, random_state=42)\n",
    "        ,\n",
    "        'params': {\n",
    "            'forecaster__estimator__loss': ['linear', 'square', 'exponential'],\n",
    "            'forecaster__estimator__n_estimators': [10, 50, 100, 200],\n",
    "            'forecaster__estimator__learning_rate': [0.1, 0.05, 0.01],\n",
    "        }     \n",
    "    },      \n",
    "    'lgb_regressor': {\n",
    "        'estimator': \n",
    "            lgbm.sklearn.LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, importance_type='split', learning_rate=0.1, max_depth=-1, \n",
    "                                       min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31, objective=None, \n",
    "                                       random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn', subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
    "        ,\n",
    "        'params': {\n",
    "            'forecaster__estimator__max_depth': [1, 2, 3, 4, 5, 10, -1],\n",
    "            'forecaster__estimator__num_leaves': [2, 3, 10, 20, 31, 100],\n",
    "            'forecaster__estimator__min_child_samples': [5, 10, 20, 50],\n",
    "            'forecaster__estimator__min_child_weight': [0.001, 0.005],\n",
    "            'forecaster__estimator__n_estimators': [10, 50, 100, 200],\n",
    "        }     \n",
    "    },   \n",
    "    'knn': {\n",
    "        'estimator': \n",
    "            KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=-1, n_neighbors=5, p=2, weights='uniform')\n",
    "        ,\n",
    "        'params': {\n",
    "            'forecaster__estimator__n_neighbors': [3, 5, 7, 9, 11, 13, 15, 17, 19, 21],\n",
    "            'forecaster__estimator__p': [1, 2, 3],\n",
    "        }     \n",
    "    },    \n",
    "    'passive_aggressive': {\n",
    "        'estimator': \n",
    "            PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False, epsilon=0.1, fit_intercept=True, loss='epsilon_insensitive', max_iter=1000, \n",
    "                                       n_iter_no_change=5, random_state=42, shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "        ,\n",
    "        'params': {\n",
    "            'forecaster__estimator__C': [0.1, 0.25, 0.5, 0.75, 1],\n",
    "            'forecaster__estimator__early_stopping': [True, False],\n",
    "            'forecaster__estimator__epsilon': [0.01, 0.05, 0.1, 0.2],\n",
    "            'forecaster__estimator__max_iter': [500, 1000, 2000],\n",
    "            'forecaster__estimator__n_iter_no_change': [1, 2, 3, 4, 5, 7],\n",
    "            'forecaster__estimator__validation_fraction': [0.1, 0.2],\n",
    "            'forecaster__estimator__tol': [None, 0.001, 0.002],\n",
    "        }     \n",
    "    },       \n",
    "    'huber': {\n",
    "        'estimator': \n",
    "            HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100, tol=1e-05, warm_start=False)\n",
    "        ,\n",
    "        'params': {\n",
    "            'forecaster__estimator__alpha': [0.00005, 0.0001, 0.0005, 0.001],\n",
    "            'forecaster__estimator__early_epsilon': [1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2],\n",
    "            'forecaster__estimator__max_iter': [50, 100, 200, 500],\n",
    "            'forecaster__estimator__tol': [1e-05, 1e-06, 5e-05, 5e-04],\n",
    "            'forecaster__estimator__warm_start': [True, False],\n",
    "        }     \n",
    "    },     \n",
    "    'bayesian_ridge': {\n",
    "        'estimator': \n",
    "            BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=False, copy_X=True, fit_intercept=True, lambda_1=1e-06, \n",
    "                          lambda_2=1e-06, lambda_init=None, n_iter=300, normalize=False, tol=0.001, verbose=False)\n",
    "        ,\n",
    "        'params': {\n",
    "            'forecaster__estimator__alpha_1': [1e-05, 5e-05, 1e-06, 5e-06],\n",
    "            'forecaster__estimator__alpha_2': [1e-05, 5e-05, 1e-06, 5e-06],\n",
    "            'forecaster__estimator__lambda_1': [1e-05, 5e-05, 1e-06, 5e-06],\n",
    "            'forecaster__estimator__lambda_2': [1e-05, 5e-05, 1e-06, 5e-06],\n",
    "            'forecaster__estimator__compute_score': [True, False],\n",
    "            'forecaster__estimator__n_iter': [100, 200, 300, 400],\n",
    "            'forecaster__estimator__tol': [0.0005, 0.001, 0.005, 0.01, 0.05],\n",
    "        }     \n",
    "    },        \n",
    "    'lasso_lars': {\n",
    "        'estimator': \n",
    "            LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True, jitter=None, max_iter=500, \n",
    "                      normalize=True, positive=False, precompute='auto', random_state=42, verbose=False)\n",
    "        ,\n",
    "        'params': {\n",
    "            'forecaster__estimator__alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2],\n",
    "            'forecaster__estimator__max_iter': [10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "        }     \n",
    "    },        \n",
    "    'lars': {\n",
    "        'estimator': \n",
    "            Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True, jitter=None, n_nonzero_coefs=500, \n",
    "                 normalize=True, precompute='auto', random_state=42, verbose=False)\n",
    "        ,\n",
    "        'params': {\n",
    "            'forecaster__estimator__n_nonzero_coefs': [1, 5, 10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "        }     \n",
    "    },       \n",
    "    'elastic_net': {\n",
    "        'estimator': \n",
    "            ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5, max_iter=1000, normalize=False, positive=False, \n",
    "                       precompute=False, random_state=42, selection='cyclic', tol=0.0001, warm_start=False)\n",
    "        ,\n",
    "        'params': {\n",
    "            'forecaster__estimator__alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2],\n",
    "            'forecaster__estimator__l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "            'forecaster__estimator__max_iter': [10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "            'forecaster__estimator__tol': [0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005],\n",
    "            'forecaster__estimator__warm_start': [True, False],\n",
    "        }     \n",
    "    },        \n",
    "    'ridge': {\n",
    "        'estimator': \n",
    "            Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, normalize=False, random_state=42, solver='auto', tol=0.001)\n",
    "        ,\n",
    "        'params': {\n",
    "            'forecaster__estimator__alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2],\n",
    "            'forecaster__estimator__max_iter': [10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "            'forecaster__estimator__tol': [0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005],\n",
    "        }     \n",
    "    },     \n",
    "    'lasso': {\n",
    "        'estimator': \n",
    "            Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, normalize=False, positive=False, precompute=False, \n",
    "                  random_state=42, selection='cyclic', tol=0.0001, warm_start=False)\n",
    "        ,\n",
    "        'params': {\n",
    "            'forecaster__estimator__alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2],\n",
    "            'forecaster__estimator__max_iter': [10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "            'forecaster__estimator__tol': [0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005],\n",
    "            'forecaster__estimator__warm_start': [True, False],\n",
    "        }     \n",
    "    },        \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc14ca8-13d7-4d34-bc97-7b3db5a56c57",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc046990-f317-43bd-906e-4ca455adfef5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'date' was removed from Satellite.\n",
      "###################################################################### sla ######################################################################\n",
      "train datetime margins              : 1993-01 - 2017-12.     Total samples: 300 (89.3%)\n",
      "test datetime margins               : 2018-01 - 2020-12.     Total samples: 36 (10.7%)\n",
      "valid datetime margins              : 2015-01 - 2017-12.     Total samples: 36 (10.7%)\n",
      "train_without_valid datetime margins: 1993-01 - 2014-12.     Total samples: 264 (78.6%)\n",
      "decision_tree\n",
      "DirectTabularRegressionForecaster(estimator=DecisionTreeRegressor(random_state=42))\n",
      "{'forecaster__window_length': [12, 24, 36, 48]}\n",
      "Fitting 36 folds for each of 4 candidates, totalling 144 fits\n",
      "24\n",
      "random_forest\n",
      "DirectTabularRegressionForecaster(estimator=RandomForestRegressor(n_jobs=-1,\n",
      "                                                                  random_state=42))\n",
      "{'forecaster__window_length': [12, 24, 36, 48]}\n",
      "Fitting 36 folds for each of 4 candidates, totalling 144 fits\n",
      "24\n",
      "extra_trees\n",
      "DirectTabularRegressionForecaster(estimator=ExtraTreesRegressor(n_jobs=-1,\n",
      "                                                                random_state=42))\n",
      "{'forecaster__window_length': [12, 24, 36, 48]}\n",
      "Fitting 36 folds for each of 4 candidates, totalling 144 fits\n",
      "48\n",
      "gradient_boosting\n",
      "DirectTabularRegressionForecaster(estimator=GradientBoostingRegressor(random_state=42))\n",
      "{'forecaster__window_length': [12, 24, 36, 48]}\n",
      "Fitting 36 folds for each of 4 candidates, totalling 144 fits\n",
      "36\n",
      "adaboost\n",
      "DirectTabularRegressionForecaster(estimator=AdaBoostRegressor(random_state=42))\n",
      "{'forecaster__window_length': [12, 24, 36, 48]}\n",
      "Fitting 36 folds for each of 4 candidates, totalling 144 fits\n",
      "24\n",
      "lgb_regressor\n",
      "DirectTabularRegressionForecaster(estimator=LGBMRegressor(random_state=42))\n",
      "{'forecaster__window_length': [12, 24, 36, 48]}\n",
      "Fitting 36 folds for each of 4 candidates, totalling 144 fits\n",
      "24\n",
      "knn\n",
      "DirectTabularRegressionForecaster(estimator=KNeighborsRegressor(n_jobs=-1))\n",
      "{'forecaster__window_length': [12, 24, 36, 48]}\n",
      "Fitting 36 folds for each of 4 candidates, totalling 144 fits\n",
      "12\n",
      "passive_aggressive\n",
      "DirectTabularRegressionForecaster(estimator=PassiveAggressiveRegressor(random_state=42))\n",
      "{'forecaster__window_length': [12, 24, 36, 48]}\n",
      "Fitting 36 folds for each of 4 candidates, totalling 144 fits\n",
      "24\n",
      "huber\n",
      "DirectTabularRegressionForecaster(estimator=HuberRegressor())\n",
      "{'forecaster__window_length': [12, 24, 36, 48]}\n",
      "Fitting 36 folds for each of 4 candidates, totalling 144 fits\n",
      "24\n",
      "bayesian_ridge\n",
      "DirectTabularRegressionForecaster(estimator=BayesianRidge())\n",
      "{'forecaster__window_length': [12, 24, 36, 48]}\n",
      "Fitting 36 folds for each of 4 candidates, totalling 144 fits\n",
      "12\n",
      "lasso_lars\n",
      "DirectTabularRegressionForecaster(estimator=LassoLars(random_state=42))\n",
      "{'forecaster__window_length': [12, 24, 36, 48]}\n",
      "Fitting 36 folds for each of 4 candidates, totalling 144 fits\n",
      "48\n",
      "lars\n",
      "DirectTabularRegressionForecaster(estimator=Lars(random_state=42))\n",
      "{'forecaster__window_length': [12, 24, 36, 48]}\n",
      "Fitting 36 folds for each of 4 candidates, totalling 144 fits\n",
      "12\n",
      "elastic_net\n",
      "DirectTabularRegressionForecaster(estimator=ElasticNet(random_state=42))\n",
      "{'forecaster__window_length': [12, 24, 36, 48]}\n",
      "Fitting 36 folds for each of 4 candidates, totalling 144 fits\n",
      "48\n",
      "ridge\n",
      "DirectTabularRegressionForecaster(estimator=Ridge(random_state=42))\n",
      "{'forecaster__window_length': [12, 24, 36, 48]}\n",
      "Fitting 36 folds for each of 4 candidates, totalling 144 fits\n",
      "12\n",
      "lasso\n",
      "DirectTabularRegressionForecaster(estimator=Lasso(random_state=42))\n",
      "{'forecaster__window_length': [12, 24, 36, 48]}\n",
      "Fitting 36 folds for each of 4 candidates, totalling 144 fits\n",
      "48\n",
      "###################################################################### ugosa ######################################################################\n",
      "train datetime margins              : 1993-01 - 2017-12.     Total samples: 300 (89.3%)\n",
      "test datetime margins               : 2018-01 - 2020-12.     Total samples: 36 (10.7%)\n",
      "valid datetime margins              : 2015-01 - 2017-12.     Total samples: 36 (10.7%)\n",
      "train_without_valid datetime margins: 1993-01 - 2014-12.     Total samples: 264 (78.6%)\n",
      "decision_tree\n",
      "DirectTabularRegressionForecaster(estimator=DecisionTreeRegressor(random_state=42))\n",
      "{'forecaster__window_length': [12, 24, 36, 48]}\n",
      "Fitting 36 folds for each of 4 candidates, totalling 144 fits\n",
      "12\n",
      "random_forest\n",
      "DirectTabularRegressionForecaster(estimator=RandomForestRegressor(n_jobs=-1,\n",
      "                                                                  random_state=42))\n",
      "{'forecaster__window_length': [12, 24, 36, 48]}\n",
      "Fitting 36 folds for each of 4 candidates, totalling 144 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11568\\2980863940.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m         )\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mgscv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgscv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_forecaster_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'forecaster'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'window_length'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# Save models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\forecasting\\lib\\site-packages\\sktime\\forecasting\\base\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y, X, fh)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;31m#####################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_inner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_inner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;31m# this should happen last\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\forecasting\\lib\\site-packages\\sktime\\forecasting\\model_selection\\_tune.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, y, X, fh, **fit_params)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;31m# Run grid-search cross-validation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\forecasting\\lib\\site-packages\\sktime\\forecasting\\model_selection\\_tune.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m         \u001b[0m_check_param_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\forecasting\\lib\\site-packages\\sktime\\forecasting\\model_selection\\_tune.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             out = parallel(\n\u001b[1;32m--> 243\u001b[1;33m                 \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_fit_and_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcandidate_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m             )\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\forecasting\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\forecasting\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\forecasting\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\forecasting\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\forecasting\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tune_only_window_length = True\n",
    "fast = False\n",
    "\n",
    "# define forecastin horizon\n",
    "fh = 1\n",
    "\n",
    "# Read Data\n",
    "dataset_name = 'Satellite'\n",
    "data, seasonal_period, freq_sktime = read_file(dataset_name, data_path='G:/My Drive/PhD/ECOSCOPE/time-series-forecasting-waves/data/')\n",
    "preprocess = False\n",
    "\n",
    "# ONLY FOR SKTIME\n",
    "# keep datetime as a column for plots\n",
    "data['datetime'] = data.index\n",
    "data.index = pd.PeriodIndex(data.index, freq=freq_sktime)\n",
    "\n",
    "# metric\n",
    "mase = MeanAbsoluteScaledError(sp=seasonal_period)\n",
    "\n",
    "for target in data.drop(columns=['datetime']):\n",
    "    print('#'*70, target, '#'*70)\n",
    "\n",
    "    # split data\n",
    "    train, test, valid, train_without_valid, train_test_split_date, train_valid_split_date = train_valid_test_split(dataset_name, data)\n",
    "\n",
    "    if fast is True:\n",
    "        initial_window = train[:train.shape[0]-seasonal_period].shape[0]\n",
    "    else:\n",
    "        initial_window = train_without_valid.shape[0]\n",
    "\n",
    "    # expanding window to fit test data\n",
    "    cv = ExpandingWindowSplitter(step_length=1, fh=fh, initial_window=initial_window)\n",
    "    min_max_scaler = TabularToSeriesAdaptor(MinMaxScaler(feature_range=(1, 2)))\n",
    "\n",
    "    for algorithm_name, value in algorithms.items():\n",
    "        print(algorithm_name)\n",
    "\n",
    "        estimator = DirectTabularRegressionForecaster(estimator=value['estimator'])\n",
    "\n",
    "        pipe = TransformedTargetForecaster(steps=[\n",
    "            # (\"detrender\", Detrender()),\n",
    "            # (\"deseasonalizer\", Differencer(lags=1)),\n",
    "            (\"minmaxscaler\", min_max_scaler),\n",
    "            (\"forecaster\", estimator),\n",
    "        ])\n",
    "        print(estimator)\n",
    "        if seasonal_period == 1:\n",
    "            window_size = 7\n",
    "        elif seasonal_period == 12 or seasonal_period == 24:\n",
    "            window_size = seasonal_period\n",
    "        \n",
    "        if tune_only_window_length is True:\n",
    "            param_grid = {\"forecaster__window_length\": [i*window_size for i in range(1,5)]}\n",
    "        else:\n",
    "            param_grid = value['params']\n",
    "            param_grid['forecaster__window_length'] = [i*window_size for i in range(1,5)]\n",
    "        print(param_grid)\n",
    "        gscv = ForecastingGridSearchCV(\n",
    "            forecaster = pipe, \n",
    "            strategy = \"refit\", \n",
    "            cv = cv, \n",
    "            param_grid = param_grid,\n",
    "            scoring = mase,\n",
    "            n_jobs = -2,\n",
    "            verbose=2\n",
    "        )\n",
    "\n",
    "        gscv.fit(train[target], fh=fh)\n",
    "        print(gscv.best_forecaster_.get_params()['forecaster'].get_params()['window_length'])\n",
    "        # Save models\n",
    "        # if tune_only_window_length is True:\n",
    "            # pd.to_pickle(gscv.best_forecaster_, f'../../results/tuned_models/just_window/{dataset_name}/{target}.{algorithm_name}.pkl')\n",
    "        # else:\n",
    "            # pd.to_pickle(gscv.best_forecaster_, f'../../results/tuned_models/window_and_algorithm/{dataset_name}/{target}.{algorithm_name}.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff8938d-a9f9-4149-982c-1c42d0fa75eb",
   "metadata": {},
   "source": [
    "## Read saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5fd778-e372-4968-9420-a6cea80b069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pd.read_pickle(f'../../results/tuned_models/just_window/{dataset_name}/{target}.decision_tree.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5b209-dca2-44f0-a689-e7ed700384af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6dc62b-43b1-4215-bd91-22805617e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()['forecaster'].get_params()['window_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596468de-16dc-436a-819a-02762c12f67d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
